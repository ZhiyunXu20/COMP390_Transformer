{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KQ4DDnreYfzK3cicJtrrbXOSIY5juDsY","timestamp":1729676378396}],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMV_YJy4GMrE","executionInfo":{"status":"ok","timestamp":1730127592280,"user_tz":0,"elapsed":26379,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"bdf88314-77d7-46c8-d0da-71dfd24bf8ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","import os\n","\n","sys.path.append(\"/content/drive/MyDrive/transformer\")\n","# Change working directory to the script's location\n","os.chdir(\"/content/drive/MyDrive/transformer\")\n","\n","# raw data\n","# path_do_data = \"data/english.txt\"\n","path_do_data = \"data/80652__REPORT__A5-2001-0263__EN.txt\"\n","\n","data_raw = open(path_do_data, encoding=\"utf-8\").read()"],"metadata":{"id":"_UPkK4KyMRFC","executionInfo":{"status":"ok","timestamp":1730127626951,"user_tz":0,"elapsed":485,"user":{"displayName":"liuyu","userId":"09439856996209072607"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/transformer/requirements.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zdfyfnvMURN","executionInfo":{"status":"ok","timestamp":1730127635193,"user_tz":0,"elapsed":3470,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"a87afedb-24bf-4bda-a19d-e37d2c2880b3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (2.5.0+cu121)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (4.44.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/transformer/requirements.txt (line 4)) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (0.24.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (4.66.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/drive/MyDrive/transformer/requirements.txt (line 3)) (2024.8.30)\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/transformer/train_model.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcwMsK_lMra4","executionInfo":{"status":"ok","timestamp":1730128044679,"user_tz":0,"elapsed":384756,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"3f58cb81-a799-4c04-8094-a4a829f69a19"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\rtokenizer_config.json:   0% 0.00/48.0 [00:00<?, ?B/s]\rtokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 381kB/s]\n","\rconfig.json:   0% 0.00/570 [00:00<?, ?B/s]\rconfig.json: 100% 570/570 [00:00<00:00, 5.63MB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 5.12MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 15.6MB/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1239778 > 512). Running this sequence through the model will result in indexing errors\n","Model with 89.48M parameters\n","Training Progress:   0% 0/5000 [00:00<?, ?it/s]step          0 | train loss 10.7007 | val loss 10.6863\n","Training Progress:  10% 499/5000 [00:37<05:22, 13.97it/s]step        500 | train loss 2.9047 | val loss 4.7689\n","Training Progress:  20% 999/5000 [01:12<04:37, 14.40it/s]step       1000 | train loss 2.3215 | val loss 4.3993\n","Training Progress:  30% 1499/5000 [01:48<04:06, 14.22it/s]step       1500 | train loss 2.0164 | val loss 4.3706\n","Training Progress:  40% 1999/5000 [02:23<03:31, 14.21it/s]step       2000 | train loss 1.7434 | val loss 4.2752\n","Training Progress:  50% 2499/5000 [02:59<02:57, 14.12it/s]step       2500 | train loss 1.6479 | val loss 4.2105\n","Training Progress:  60% 2999/5000 [03:35<02:21, 14.17it/s]step       3000 | train loss 1.5989 | val loss 4.1948\n","Training Progress:  70% 3499/5000 [04:11<01:45, 14.25it/s]step       3500 | train loss 1.3815 | val loss 4.2340\n","Training Progress:  80% 3999/5000 [04:47<01:10, 14.14it/s]step       4000 | train loss 1.2842 | val loss 4.3859\n","Training Progress:  90% 4499/5000 [05:22<00:35, 14.21it/s]step       4500 | train loss 1.1607 | val loss 4.5770\n","Training Progress: 100% 4999/5000 [05:58<00:00, 14.25it/s]step       4999 | train loss 1.1366 | val loss 4.6070\n","Training Progress: 100% 5000/5000 [05:59<00:00, 13.92it/s]\n","Successfully saved the model to checkpoints/checkpoint_epoch-4999_28.10.2024_15:07:16.pt\n","2024-10-28 15:07:20.315022: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-10-28 15:07:20.333257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-28 15:07:20.354777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-28 15:07:20.361292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-28 15:07:20.376859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-10-28 15:07:21.529581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[PAD] on the table. tell tom to thank everyone who speaks french. thank you for the reason you could learn french. thank you for this much of your concern. thanks to me for going to throw your business. thanks to reading this letter by accident. thanks to her, i saved your first. thanks to everything i life. thanks to her, i should ask him out. thanks. thanks to me, i could barely stand? thanks. thanks to him, he said it. thanks to her.\n"]}]},{"cell_type":"code","source":["# load the model\n","import json\n","import torch\n","from transformers import AutoTokenizer\n","from model import Transformer\n","# from train_model import vocab_size\n","from utils import (\n","    BATCH_SIZE,\n","    BLOCK_SIZE,\n","    DEVICE,\n","    DROPOUT,\n","    LEARNING_RATE,\n","    NUM_EMBED,\n","    NUM_HEAD,\n","    NUM_LAYER,\n","    MAX_ITER,\n","    EVAL_INTER,\n","    load_model_from_checkpoint,\n","    decode,\n",")"],"metadata":{"id":"OMlC6c_cVztv","executionInfo":{"status":"ok","timestamp":1730128140534,"user_tz":0,"elapsed":2426,"user":{"displayName":"liuyu","userId":"09439856996209072607"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# set parameter\n","\n","# device path_to_checkpoint(need check and change every time!!) vocab_path\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","path_to_checkpoint = \"/content/drive/MyDrive/transformer/checkpoints/checkpoint_epoch-4999_28.10.2024_15:07:16.pt\"\n","vocab_path = \"bert-base-uncased\"\n","\n","# find vocab_size\n","with open(\"/content/drive/MyDrive/transformer/checkpoints/vocab_info.json\", \"r\") as f:\n","    vocab_info = json.load(f)\n","vocab_size = vocab_info[\"vocab_size\"]\n","\n","# tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(vocab_path)\n","vocab_size = tokenizer.vocab_size\n","\n","# parameter\n","model = Transformer(\n","    vocab_size=vocab_size,\n","    num_embed=NUM_EMBED,\n","    block_size=BLOCK_SIZE,\n","    num_heads=NUM_HEAD,\n","    num_layers=NUM_LAYER,\n","    dropout=DROPOUT,\n",").to(DEVICE)\n","\n","# load_model_from_checkpoint\n","model = load_model_from_checkpoint(\n","    model_class=Transformer,\n","    path_to_checkpoint=path_to_checkpoint,\n","    vocab_size=vocab_size,\n","    num_embed=NUM_EMBED,\n","    block_size=BLOCK_SIZE,\n","    num_heads=NUM_HEAD,\n","    num_layers=NUM_LAYER,\n","    dropout=DROPOUT\n",")"],"metadata":{"id":"IsPX6PGTV9Is","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730129129627,"user_tz":0,"elapsed":5729,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"e9b1616b-b245-4482-c900-476152f1c4af"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded model from the checkpoint\n"]}]},{"cell_type":"code","source":["model.to(DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F45BqUae6JdL","executionInfo":{"status":"ok","timestamp":1730129155707,"user_tz":0,"elapsed":231,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"32528baa-20fa-4716-9a48-8abf1456eda7"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Transformer(\n","  (token_embedding_table): Embedding(30522, 768)\n","  (position_embedding_table): Embedding(64, 768)\n","  (blocks): Sequential(\n","    (0): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (4): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (5): TransformerBlock(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-5): 6 x AttentionHead(\n","            (key): Linear(in_features=768, out_features=128, bias=False)\n","            (query): Linear(in_features=768, out_features=128, bias=False)\n","            (value): Linear(in_features=768, out_features=128, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedForward(\n","        (net): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=768, out_features=30522, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# # check load or not\n","# # skip this,next also run sucessfully??\n","\n","# if model is not None:\n","#     model.to(DEVICE)\n","\n","#     # parameters\n","#     for param in model.parameters():\n","#         assert param.device == torch.device(DEVICE), \"Model parameter is not on the correct device\"\n","\n","#     # generate\n","#     context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","#     generated_tokens = model.generate(idx=context, max_new_tokens=100, block_size=BLOCK_SIZE)[0]\n","#     generated_text = decode(enc_sec=generated_tokens, tokenizer=AutoTokenizer.from_pretrained(vocab_path))\n","\n","#     print(\"Can Generated text:\\n\", generated_text)\n","# else:\n","#     print(\"Failed to load the model from the checkpoint.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"-lEIl6gANX-g","executionInfo":{"status":"error","timestamp":1730129620741,"user_tz":0,"elapsed":235,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"b73cb0ad-7578-4248-9369-aafd2a39d9a9","collapsed":true},"execution_count":27,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Model parameter is not on the correct device","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-47c22a620400>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model parameter is not on the correct device\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Model parameter is not on the correct device"]}]},{"cell_type":"code","source":["# context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n","context = torch.zeros((1, 1), dtype=torch.long).to(DEVICE)\n","generated_tokens = model.generate(idx=context, max_new_tokens=100, block_size=BLOCK_SIZE)[0]\n","generated_text = decode(enc_sec=generated_tokens, tokenizer=tokenizer)\n","\n","print(\"Generated text:\\n\", generated_text)"],"metadata":{"id":"oiN9CNwUWGTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730129656962,"user_tz":0,"elapsed":2351,"user":{"displayName":"liuyu","userId":"09439856996209072607"}},"outputId":"2a6c9f6d-b71f-40ea-929c-c51423b38027"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text:\n"," [PAD] on my favorite authors? do you think i would find work for me? do you think i would find work for me? do you think i'll give it another try? do you think it's a good idea? do you think we need old enough? do you think you have a good appetite? do you think you have a good friend? do you think you have a good day? do you usually have a good day? do you want to listen to me? do you want\n"]}]}]}